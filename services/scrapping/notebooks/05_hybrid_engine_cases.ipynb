{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "**Run on Google Colab (Quickstart)**\n",
    "\n",
    "```bash\n",
    "! git clone --branch main --single-branch https://github.com/sbaaihamza/scrapping-lib.git\n",
    "%cd scrapping-lib\n",
    "! pip install -e \".[browser,dev]\"\n",
    "! playwright install\n",
    "# Preferred (installs OS deps automatically on supported distros):\n",
    "! playwright install --with-deps chromium\n",
    "# If needed (manual deps fallback):\n",
    "! apt-get update\n",
    "! apt-get install -y libxcomposite1 libxcursor1 libgtk-3-0 libatk1.0-0 libcairo2 libgdk-pixbuf2.0-0\n",
    "%cd /content/scrapping-lib/notebooks\n",
    "```\n",
    "\n",
    "*Note: Playwright has both sync and async APIs. These notebooks are designed to be async-safe for Jupyter/Colab. If you encounter OS dependency issues, use the `playwright install --with-deps chromium` command.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6b63f7",
   "metadata": {},
   "source": [
    "# Engine In-Depth: Hybrid Engine Cases\n",
    "\n",
    "This notebook demonstrates the `hybrid` engine, combining the speed of HTTP discovery with the accuracy of Browser detail extraction.\n",
    "\n",
    "### Learning Outcomes\n",
    "*   Understand when a **Hybrid approach** is justified (High speed vs. High accuracy).\n",
    "*   Configure **Fallback Policies** based on content quality.\n",
    "*   Implement **Diagnostics-driven Fallbacks** (e.g., if HTTP reports `js_required`).\n",
    "*   Interpret **Multi-engine Traces** for full observability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-code",
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport os\nimport sys\nfrom pathlib import Path\n\nfrom scrapping.diagnostics.classifiers import DiagnosisLabel\nfrom scrapping.engines.hybrid import HybridEngine, HybridEngineOptions\n\nREPO_ROOT = Path.cwd().parent\nsys.path.append(str(REPO_ROOT))\nos.chdir(str(REPO_ROOT))\n\nONLINE = os.getenv('ONLINE', '0') == '1'\nRESULTS_DIR = Path('results_notebook_hybrid')\nprint(f'Online mode: {ONLINE}')"
  },
  {
   "cell_type": "markdown",
   "id": "case0",
   "metadata": {},
   "source": [
    "## 1) Why Hybrid?\n",
    "\n",
    "We use **HTTP** for fast link discovery (Listing pages) and **Browser** for accurate content extraction (Detail pages). This minimizes resource consumption while ensuring data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-init",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = HybridEngine()\n",
    "\n",
    "url_list = 'https://quotes.toscrape.com/'\n",
    "url_detail = 'https://quotes.toscrape.com/author/Albert-Einstein/'\n",
    "\n",
    "if ONLINE:\n",
    "    res_list = engine.get(url_list)\n",
    "    print(f\"Listing (HTTP) OK: {res_list.ok}\")\n",
    "    \n",
    "    res_det = engine.get_rendered(url_detail)\n",
    "    print(f\"Detail (Browser) OK: {res_det.ok}\")\n",
    "else:\n",
    "    print(\"Offline: Engine initialized. Use fixtures for multi-engine simulation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallback-strategy",
   "metadata": {},
   "source": [
    "## 2) Fallback Behavior\n",
    "\n",
    "The Hybrid engine can automatically fallback to Browser if HTTP fails or returns low-quality content (e.g., body length < 500 chars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallback-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = HybridEngineOptions(\n",
    "    fallback_to_browser=True, \n",
    "    min_text_len=500\n",
    ")\n",
    "engine_fb = HybridEngine(options=opts)\n",
    "print(f\"Hybrid configured with fallback. Min text len: {opts.min_text_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostics-fallback",
   "metadata": {},
   "source": [
    "## 3) Diagnostics-Driven Fallback\n",
    "\n",
    "Modern scrapers use signals to decide when to escalate. \n",
    "*   If HTTP reports `js_required_or_missing_content` -> **Switch to Browser**.\n",
    "*   If `challenge_detected` -> **Stop immediately**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostics-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapping.diagnostics.classifiers import diagnose_http_response\n",
    "\n",
    "\n",
    "def smart_get(url, engine):\n",
    "    res = engine.http.get(url)\n",
    "    diag = diagnose_http_response(res.status_code, res.response_meta.headers, res.text)\n",
    "    \n",
    "    if diag.label == DiagnosisLabel.JS_REQUIRED_OR_MISSING_CONTENT:\n",
    "        print(f\"Escalating {url} to Browser engine...\")\n",
    "        return engine.browser.get(url)\n",
    "    elif diag.label == DiagnosisLabel.CHALLENGE_DETECTED:\n",
    "        print(f\"Challenge detected on {url}. Stopping.\")\n",
    "        return res\n",
    "    \n",
    "    return res\n",
    "\n",
    "print(\"Smart fetching logic defined based on diagnostic signals.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "observability",
   "metadata": {},
   "source": [
    "## 4) Observability: Multi-engine Traces\n",
    "\n",
    "Results from a Hybrid engine include a combined trace showing exactly which engine was used and why fallbacks were triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trace-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ONLINE:\n",
    "    res = engine_fb.get('https://example.com')\n",
    "    print(f\"Engine Trace: {json.dumps(res.engine_trace, indent=2)}\")\n",
    "else:\n",
    "    print(\"Offline: Trace would show the sequence of engine attempts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verification-checklist",
   "metadata": {},
   "source": [
    "### Verification Checklist\n",
    "- [ ] HTTP discovery is used for listing pages to save resources.\n",
    "- [ ] Browser rendering is used for detail pages or as a validated fallback.\n",
    "- [ ] Diagnostics correctly trigger engine escalation.\n",
    "- [ ] Combined traces provide full visibility into the execution path."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
