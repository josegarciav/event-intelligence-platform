{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "**Run on Google Colab (Quickstart)**\n",
    "\n",
    "```bash\n",
    "! git clone --branch main --single-branch https://github.com/sbaaihamza/scrapping-lib.git\n",
    "%cd scrapping-lib\n",
    "! pip install -e \".[browser,dev]\"\n",
    "! playwright install\n",
    "# Preferred (installs OS deps automatically on supported distros):\n",
    "! playwright install --with-deps chromium\n",
    "# If needed (manual deps fallback):\n",
    "! apt-get update\n",
    "! apt-get install -y libxcomposite1 libxcursor1 libgtk-3-0 libatk1.0-0 libcairo2 libgdk-pixbuf2.0-0\n",
    "%cd /content/scrapping-lib/notebooks\n",
    "```\n",
    "\n",
    "*Note: Playwright has both sync and async APIs. These notebooks are designed to be async-safe for Jupyter/Colab. If you encounter OS dependency issues, use the `playwright install --with-deps chromium` command.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e465cf9f",
   "metadata": {},
   "source": [
    "# End-to-End Scraping Pipeline Walkthrough\n",
    "\n",
    "This notebook demonstrates the `scrapping` library's full pipeline using a concrete multi-source configuration.\n",
    "\n",
    "### Purpose\n",
    "- Explain the core components of the library.\n",
    "- Demonstrate how to load, validate, and execute scraping configurations.\n",
    "- Show the transition from raw HTML to structured, quality-filtered data.\n",
    "\n",
    "### Output Directory\n",
    "Results from this notebook will be written to `results_notebook/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ec8ac",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n",
    "We start by importing the necessary modules and setting up our environment. We use robust path detection to ensure the notebook works regardless of where it's launched from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f014f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scrapping.config.migration import migrate_config\n",
    "from scrapping.extraction.link_extractors import LinkExtractRequest, extract_links\n",
    "from scrapping.orchestrator import Orchestrator, OrchestratorOptions, validate_config\n",
    "from scrapping.processing.html_to_structured import html_to_structured\n",
    "from scrapping.processing.quality_filters import evaluate_quality\n",
    "\n",
    "\n",
    "# Robust path detection to find repo root\n",
    "def find_repo_root(start_path):\n",
    "    p = Path(start_path).resolve()\n",
    "    for parent in [p] + list(p.parents):\n",
    "        if (parent / \"pyproject.toml\").exists():\n",
    "            return parent\n",
    "    return p\n",
    "\n",
    "\n",
    "REPO_ROOT = find_repo_root(Path.cwd())\n",
    "sys.path.append(str(REPO_ROOT))\n",
    "os.chdir(str(REPO_ROOT))\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Repo root: {REPO_ROOT}\")\n",
    "\n",
    "# Toggle between offline and online mode\n",
    "ONLINE = os.getenv(\"ONLINE\", \"0\") == \"1\"\n",
    "print(f\"Online mode: {ONLINE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa2ef4a",
   "metadata": {},
   "source": [
    "## 2. Load and Explain the Config\n",
    "We load the multi-source job sites configuration. We also apply migrations to see the resolved version of the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3390070",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"examples/configs/example_multi_sources.json\"\n",
    "with open(config_path) as f:\n",
    "    raw_cfg = json.load(f)\n",
    "\n",
    "cfg, was_migrated = migrate_config(raw_cfg)\n",
    "print(f\"Config migrated: {was_migrated}\")\n",
    "\n",
    "sources_data = []\n",
    "for s in cfg[\"sources\"]:\n",
    "    eng = s.get(\"engine\", {})\n",
    "    disc = s.get(\"discovery\", {})\n",
    "    le = disc.get(\"link_extract\", {})\n",
    "    sources_data.append(\n",
    "        {\n",
    "            \"source_id\": s[\"source_id\"],\n",
    "            \"engine_type\": eng.get(\"type\"),\n",
    "            \"entrypoint\": s[\"entrypoints\"][0][\"url\"],\n",
    "            \"link_extract_method\": le.get(\"method\"),\n",
    "            \"pattern_selector\": le.get(\"pattern\") or le.get(\"selector\"),\n",
    "            \"min_text_len\": s.get(\"quality\", {}).get(\"min_text_len\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_sources = pd.DataFrame(sources_data)\n",
    "df_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d607aa",
   "metadata": {},
   "source": [
    "### Resolved Config (Post-Migration)\n",
    "Here is what one of the sources looks like after migration. Notice how fields like `config_version` and `storage` are normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390cc123",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(cfg[\"sources\"][0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f89c87",
   "metadata": {},
   "source": [
    "## 3. Validate Config\n",
    "Before running, we ensure the configuration is valid according to our schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_result = validate_config(cfg, verbose=True)\n",
    "if validation_result[\"ok\"]:\n",
    "    print(\"Config is VALID.\")\n",
    "else:\n",
    "    print(\"Config is INVALID. Issues:\")\n",
    "    for issue in validation_result[\"issues\"]:\n",
    "        lvl = issue[\"level\"].upper()\n",
    "        msg = issue[\"msg\"]\n",
    "        print(f\"- [{lvl}] {msg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab950970",
   "metadata": {},
   "source": [
    "## 4. Offline Fixtures\n",
    "In offline mode, we use local HTML files to simulate the fetching process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341400ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixture_path(kind, source_id):\n",
    "    return REPO_ROOT / f\"tests/fixtures/html/{kind}_{source_id}.html\"\n",
    "\n",
    "\n",
    "for s in cfg[\"sources\"]:\n",
    "    sid = s[\"source_id\"]\n",
    "    listing_p = get_fixture_path(\"listing\", sid)\n",
    "    detail_p = get_fixture_path(\"detail\", sid)\n",
    "    print(\n",
    "        f\"Source {sid}: Listing fixture exists: {listing_p.exists()}, Detail fixture exists: {detail_p.exists()}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd7f7a8",
   "metadata": {},
   "source": [
    "## 5. Link Extraction Demo\n",
    "We demonstrate how links are extracted from listing pages using regex or CSS selectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6318de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in cfg[\"sources\"]:\n",
    "    sid = s[\"source_id\"]\n",
    "    le_cfg = s[\"discovery\"][\"link_extract\"]\n",
    "\n",
    "    with open(get_fixture_path(\"listing\", sid)) as f:\n",
    "        html = f.read()\n",
    "\n",
    "    req = LinkExtractRequest(\n",
    "        html=html,\n",
    "        base_url=s[\"entrypoints\"][0][\"url\"],\n",
    "        method=le_cfg[\"method\"],\n",
    "        pattern=le_cfg.get(\"pattern\"),\n",
    "        selector=le_cfg.get(\"selector\"),\n",
    "        normalize=True,\n",
    "    )\n",
    "\n",
    "    links = extract_links(req)\n",
    "    print(f\"Source {sid}: Found {len(links)} links. Samples:\")\n",
    "    for url in links[:3]:\n",
    "        print(f\"  - {url}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b797b045",
   "metadata": {},
   "source": [
    "## 6. HTML -> Structured Demo\n",
    "This step converts raw HTML into a structured dictionary with title and main text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9dfb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in cfg[\"sources\"]:\n",
    "    sid = s[\"source_id\"]\n",
    "    with open(get_fixture_path(\"detail\", sid)) as f:\n",
    "        html = f.read()\n",
    "\n",
    "    doc = html_to_structured(html, url=f\"https://example.com/mock/{sid}\")\n",
    "    print(f\"Source {sid}:\")\n",
    "    print(f\"  - Title: {doc.title}\")\n",
    "    print(f\"  - Text length: {len(doc.text)}\")\n",
    "    print(f\"  - Extractor: {doc.extractor}\")\n",
    "    print(f\"  - Snippet: {doc.text[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9de3eba",
   "metadata": {},
   "source": [
    "## 7. Quality Filters Demo\n",
    "We validate the extracted items against quality rules (e.g., minimum text length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cff973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in cfg[\"sources\"]:\n",
    "    sid = s[\"source_id\"]\n",
    "    rules = s.get(\"quality\", {})\n",
    "    min_len = rules.get(\"min_text_len\", 200)\n",
    "\n",
    "    # Using dummy items to test thresholds\n",
    "    test_items = [\n",
    "        {\"title\": \"Short\", \"text\": \"Too brief.\"},  # Should fail\n",
    "        {\n",
    "            \"title\": \"Full Post\",\n",
    "            \"text\": \"A long enough post to pass the quality threshold. \" * 20,\n",
    "        },  # Should pass\n",
    "    ]\n",
    "\n",
    "    print(f\"Source {sid} (min_text_len: {min_len}):\")\n",
    "    for item in test_items:\n",
    "        res = evaluate_quality(item, rules=rules)\n",
    "        issues = [i.code for i in res.issues]\n",
    "        print(f\"  - Text length {len(item['text']):>3}: Keep={res.keep} Issues={issues}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d852ac",
   "metadata": {},
   "source": [
    "## 8. Orchestrator Dry Run\n",
    "A dry run validates the configuration and plans the run without making any network calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da9d278",
   "metadata": {},
   "outputs": [],
   "source": [
    "orch = Orchestrator(options=OrchestratorOptions(results_dir=\"results_notebook\", dry_run=True))\n",
    "out = orch.run(cfg)\n",
    "print(json.dumps(out, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4345d6b2",
   "metadata": {},
   "source": [
    "## 9. Mini Offline 'Simulated Run'\n",
    "We simulate the pipeline by manually processing our fixtures and saving the artifacts to `results_notebook/simulated_run/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29af7f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapping.storage.layouts import Layout\n",
    "from scrapping.storage.writers import WriterOptions, write_items\n",
    "\n",
    "sim_dir = REPO_ROOT / \"results_notebook/simulated_run\"\n",
    "layout = Layout(root=sim_dir)\n",
    "run_id = \"sim_run_001\"\n",
    "writer_opts = WriterOptions()\n",
    "\n",
    "for s in cfg[\"sources\"]:\n",
    "    sid = s[\"source_id\"]\n",
    "    print(f\"Simulating source: {sid}\")\n",
    "\n",
    "    # 1. Load detail fixture\n",
    "    with open(get_fixture_path(\"detail\", sid)) as f:\n",
    "        html = f.read()\n",
    "\n",
    "    # 2. Extract and Parse\n",
    "    doc = html_to_structured(html)\n",
    "    item = doc.as_item()\n",
    "\n",
    "    # 3. Write items\n",
    "    path = write_items(\n",
    "        layout, run_id, sid, name=\"items\", items=[item], fmt=\"jsonl\", options=writer_opts\n",
    "    )\n",
    "    print(f\"  - Items written to: {path}\")\n",
    "\n",
    "print(\"\\nSimulation complete. Artifacts saved in:\", sim_dir / f\"run_{run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bd014d",
   "metadata": {},
   "source": [
    "## 10. Optional Online Run\n",
    "If `ONLINE=1`, we execute a real scrape against the actual websites. Outputs go to `results_notebook_online/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae8a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ONLINE:\n",
    "    print(\"Running online scrape...\")\n",
    "    # Note: This executes via CLI logic to reuse parallel orchestration\n",
    "    from scrapping.cli import main\n",
    "\n",
    "    argv = [\n",
    "        \"run\",\n",
    "        \"--config\",\n",
    "        config_path,\n",
    "        \"--results\",\n",
    "        \"results_notebook_online\",\n",
    "        \"--parallelism\",\n",
    "        \"4\",\n",
    "    ]\n",
    "    main(argv)\n",
    "    print(\"Online run completed. Check results_notebook_online/ for the latest run folder.\")\n",
    "else:\n",
    "    print(\"ONLINE=0, skipping online run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b981dd54",
   "metadata": {},
   "source": [
    "## 11. Troubleshooting & Next Steps\n",
    "### When a site changes\n",
    "- **Check link extraction**: Update `discovery.link_extract` regex or selector.\n",
    "- **Check rendering**: If content is missing, use `engine: { \"type\": \"browser\" }` and add `wait_for` selectors.\n",
    "- **Adjust actions**: Use `actions` to scroll, click, or bypass simple overlays.\n",
    "\n",
    "### Future Roadmap\n",
    "- **config_agent**: Automatically generate these JSON configs by probing URLs.\n",
    "- **tests_agent**: Automatically generate golden-file tests for each source.\n",
    "- **Prefect Integration**: Scale these runs using Prefect for distributed scheduling and retries."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
